# ğŸš€ Sistema FetalCare - Testes de Carga
## Estrutura Apache JMeter Profissional para AnÃ¡lise de Performance

---

## ğŸ¯ **VisÃ£o Geral**

Este diretÃ³rio contÃ©m a **suite completa de testes de carga** do Sistema FetalCare, implementada com **Apache JMeter** para anÃ¡lise profissional de performance. Os testes avaliam o comportamento do sistema sob diferentes condiÃ§Ãµes de carga, focando em **tempo de resposta**, **taxa de erro** e **comportamento sob stress**.

### âœ… **Objetivos dos Testes**
- ğŸ“Š **Tempo de Resposta**: Medir latÃªncia em diferentes cenÃ¡rios
- âŒ **Taxa de Erro**: Avaliar estabilidade sob carga
- ğŸ”¥ **Comportamento sob Carga**: Stress testing e limites do sistema
- ğŸ“ˆ **Throughput**: RequisiÃ§Ãµes por segundo suportadas
- ğŸ§  **Performance ML**: Comportamento do modelo sob carga

---

## ğŸ“ **Estrutura dos Arquivos**

```
back-end/Testes/Carga/
â”œâ”€â”€ ğŸ“‹ README_JMETER.md              # Esta documentaÃ§Ã£o
â”œâ”€â”€ ğŸ¯ plano_teste_fetalcare.jmx     # Plano principal JMeter
â”œâ”€â”€ ğŸ“Š cenarios/                     # CenÃ¡rios especÃ­ficos
â”‚   â”œâ”€â”€ stress_test.jmx              # Teste de stress
â”‚   â”œâ”€â”€ load_test.jmx                # Teste de carga normal
â”‚   â”œâ”€â”€ spike_test.jmx               # Teste de picos
â”‚   â””â”€â”€ endurance_test.jmx           # Teste de resistÃªncia
â”œâ”€â”€ ğŸ“ dados/                        # Dados de teste
â”‚   â”œâ”€â”€ usuarios.csv                 # Dados de usuÃ¡rios
â”‚   â”œâ”€â”€ gestantes.csv                # Dados de gestantes
â”‚   â””â”€â”€ parametros_ml.csv            # ParÃ¢metros para ML
â”œâ”€â”€ ğŸ“ scripts/                      # Scripts auxiliares
â”‚   â”œâ”€â”€ run_load_tests.py            # Executor automÃ¡tico
â”‚   â”œâ”€â”€ generate_test_data.py        # Gerador de dados
â”‚   â””â”€â”€ analyze_results.py           # Analisador de resultados
â”œâ”€â”€ ğŸ“ resultados/                   # Resultados dos testes
â”‚   â”œâ”€â”€ relatorios_html/             # RelatÃ³rios HTML
â”‚   â”œâ”€â”€ logs/                        # Logs detalhados
â”‚   â””â”€â”€ graficos/                    # GrÃ¡ficos de performance
â”œâ”€â”€ ğŸ“ configuracao/                 # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ jmeter.properties            # Propriedades JMeter
â”‚   â””â”€â”€ ambiente.properties          # ConfiguraÃ§Ãµes de ambiente
â””â”€â”€ ğŸ“Š RELATORIO_PERFORMANCE.md     # RelatÃ³rio de resultados
```

---

## ğŸ› ï¸ **PrÃ©-requisitos e InstalaÃ§Ã£o**

### ğŸ“¥ **1. InstalaÃ§Ã£o do Apache JMeter**
```bash
# Download JMeter (versÃ£o 5.6.3 ou superior)
# https://jmeter.apache.org/download_jmeter.cgi

# Windows
# Extrair para C:\apache-jmeter-5.6.3
# Adicionar C:\apache-jmeter-5.6.3\bin ao PATH

# Linux/Mac
wget https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.6.3.zip
unzip apache-jmeter-5.6.3.zip
export PATH=$PATH:/path/to/apache-jmeter-5.6.3/bin
```

### ğŸ **2. DependÃªncias Python**
```bash
pip install requests pandas matplotlib seaborn jinja2 xmltodict
```

### ğŸ¥ **3. Sistema FetalCare Ativo**
```bash
# Garantir que o sistema esteja rodando
cd back-end
python app_with_database.py

# Verificar endpoints
curl http://localhost:5001/health
curl http://localhost:5001/api/gestantes
```

---

## ğŸ¯ **CenÃ¡rios de Teste Implementados**

### ğŸ“Š **1. Teste de Carga Normal (load_test.jmx)**
- **Objetivo**: Avaliar performance em condiÃ§Ãµes normais
- **UsuÃ¡rios**: 50 usuÃ¡rios simultÃ¢neos
- **DuraÃ§Ã£o**: 10 minutos
- **Ramp-up**: 2 minutos
- **Endpoints Testados**:
  - GET `/api/gestantes` (listagem)
  - POST `/api/exames` (criaÃ§Ã£o de exames)
  - POST `/api/predict` (prediÃ§Ãµes ML)

### ğŸ”¥ **2. Teste de Stress (stress_test.jmx)**
- **Objetivo**: Encontrar limites do sistema
- **UsuÃ¡rios**: 100 â†’ 500 usuÃ¡rios (incremental)
- **DuraÃ§Ã£o**: 20 minutos
- **Ramp-up**: 5 minutos
- **CritÃ©rio de Falha**: Taxa de erro > 5%

### âš¡ **3. Teste de Picos (spike_test.jmx)**
- **Objetivo**: Avaliar comportamento em picos sÃºbitos
- **UsuÃ¡rios**: 10 â†’ 200 â†’ 10 (pico sÃºbito)
- **DuraÃ§Ã£o**: 15 minutos
- **PadrÃ£o**: Carga normal com picos de 2 minutos

### ğŸƒ **4. Teste de ResistÃªncia (endurance_test.jmx)**
- **Objetivo**: Avaliar estabilidade em longo prazo
- **UsuÃ¡rios**: 30 usuÃ¡rios constantes
- **DuraÃ§Ã£o**: 2 horas
- **Foco**: Memory leaks e degradaÃ§Ã£o

---

## ğŸ“Š **MÃ©tricas Monitoradas**

### â±ï¸ **Tempo de Resposta**
- **Tempo MÃ©dio**: Meta < 500ms
- **95Âº Percentil**: Meta < 1000ms
- **99Âº Percentil**: Meta < 2000ms
- **Tempo MÃ¡ximo**: Meta < 5000ms

### âŒ **Taxa de Erro**
- **Taxa Geral**: Meta < 1%
- **Erros 4xx**: Erros de cliente
- **Erros 5xx**: Erros de servidor
- **Timeouts**: Meta < 0.5%

### ğŸ“ˆ **Throughput**
- **RequisiÃ§Ãµes/seg**: Meta > 100 req/s
- **Bytes/seg**: Monitoramento de bandwidth
- **TransaÃ§Ãµes/seg**: OperaÃ§Ãµes completas

### ğŸ§  **Performance ML**
- **Tempo PrediÃ§Ã£o**: Meta < 100ms
- **Throughput ML**: Meta > 50 prediÃ§Ãµes/s
- **Accuracy sob Carga**: Manter > 95%

---

## ğŸš€ **Como Executar os Testes**

### ğŸ¯ **MÃ©todo 1: Script AutomÃ¡tico (RECOMENDADO)**
```bash
# Executar todos os cenÃ¡rios
python scripts/run_load_tests.py --all

# Executar cenÃ¡rio especÃ­fico
python scripts/run_load_tests.py --scenario load_test

# Com relatÃ³rio automÃ¡tico
python scripts/run_load_tests.py --scenario stress_test --report
```

### ğŸ”§ **MÃ©todo 2: JMeter GUI**
```bash
# Abrir JMeter GUI
jmeter

# Carregar plano de teste
# File â†’ Open â†’ plano_teste_fetalcare.jmx

# Configurar Thread Groups
# Executar: Run â†’ Start
```

### ğŸ’» **MÃ©todo 3: JMeter Command Line**
```bash
# Teste de carga bÃ¡sico
jmeter -n -t cenarios/load_test.jmx -l resultados/load_test_results.jtl

# Com relatÃ³rio HTML
jmeter -n -t cenarios/stress_test.jmx -l resultados/stress_results.jtl -e -o resultados/relatorios_html/stress_report

# Teste completo
jmeter -n -t plano_teste_fetalcare.jmx -l resultados/complete_test.jtl -e -o resultados/relatorios_html/complete_report
```

---

## ğŸ“‹ **ConfiguraÃ§Ã£o dos Testes**

### ğŸ¯ **VariÃ¡veis de Ambiente**
```properties
# ambiente.properties
HOST=localhost
PORT=5001
PROTOCOL=http
BASE_PATH=/api

# ConfiguraÃ§Ãµes de carga
NORMAL_USERS=50
STRESS_USERS=500
SPIKE_USERS=200
ENDURANCE_USERS=30

# Timeouts
CONNECTION_TIMEOUT=5000
RESPONSE_TIMEOUT=10000
```

### âš™ï¸ **Propriedades JMeter**
```properties
# jmeter.properties
jmeter.save.saveservice.output_format=xml
jmeter.save.saveservice.response_data=false
jmeter.save.saveservice.samplerData=false
jmeter.save.saveservice.requestHeaders=false
jmeter.save.saveservice.responseHeaders=false

# Performance
jmeter.engine.nongui.maxport=4445
```

---

## ğŸ“Š **AnÃ¡lise de Resultados**

### ğŸ“ˆ **MÃ©tricas Principais**
```python
# Exemplo de anÃ¡lise automÃ¡tica
def analisar_resultados(arquivo_jtl):
    """
    Analisa resultados JMeter e gera relatÃ³rio
    """
    metricas = {
        'tempo_resposta_medio': calcular_media(tempos),
        'percentil_95': calcular_percentil(tempos, 95),
        'taxa_erro': calcular_taxa_erro(resultados),
        'throughput': calcular_throughput(resultados),
        'disponibilidade': calcular_disponibilidade(resultados)
    }
    return metricas
```

### ğŸ¯ **CritÃ©rios de AprovaÃ§Ã£o**
| MÃ©trica | Meta | CrÃ­tico |
|---------|------|---------|
| **Tempo Resposta MÃ©dio** | < 500ms | < 1000ms |
| **95Âº Percentil** | < 1000ms | < 2000ms |
| **Taxa de Erro** | < 1% | < 5% |
| **Throughput** | > 100 req/s | > 50 req/s |
| **Disponibilidade** | > 99.5% | > 99% |

---

## ğŸ” **Monitoramento Durante Testes**

### ğŸ“Š **MÃ©tricas do Sistema**
```bash
# Monitoramento de recursos
htop              # CPU e MemÃ³ria
iotop             # I/O de disco
netstat -i        # TrÃ¡fego de rede
df -h             # EspaÃ§o em disco
```

### ğŸ **Monitoramento da API**
```python
# Script de monitoramento em tempo real
import requests
import time

def monitorar_api():
    while True:
        try:
            response = requests.get('http://localhost:5001/health')
            print(f"Status: {response.status_code}, Tempo: {response.elapsed.total_seconds():.3f}s")
        except Exception as e:
            print(f"Erro: {e}")
        time.sleep(5)
```

### ğŸ§  **Monitoramento ML**
```python
# Monitoramento especÃ­fico do modelo ML
def monitorar_ml():
    """Monitor performance do modelo ML sob carga"""
    tempos_predicao = []
    acuracia_amostras = []
    
    # Coletar mÃ©tricas durante teste
    # Gerar relatÃ³rio de performance ML
```

---

## ğŸ“‹ **CenÃ¡rios de Teste Detalhados**

### ğŸ¯ **CenÃ¡rio 1: OperaÃ§Ãµes CRUD**
```xml
<!-- Exemplo de Thread Group para CRUD -->
<ThreadGroup>
    <stringProp name="ThreadGroup.num_threads">50</stringProp>
    <stringProp name="ThreadGroup.ramp_time">120</stringProp>
    <stringProp name="ThreadGroup.duration">600</stringProp>
    
    <!-- Criar Gestante -->
    <HTTPSamplerProxy>
        <stringProp name="HTTPSampler.path">/api/gestantes</stringProp>
        <stringProp name="HTTPSampler.method">POST</stringProp>
    </HTTPSamplerProxy>
    
    <!-- Listar Gestantes -->
    <HTTPSamplerProxy>
        <stringProp name="HTTPSampler.path">/api/gestantes</stringProp>
        <stringProp name="HTTPSampler.method">GET</stringProp>
    </HTTPSamplerProxy>
</ThreadGroup>
```

### ğŸ¤– **CenÃ¡rio 2: PrediÃ§Ãµes ML**
```xml
<!-- Thread Group especÃ­fico para ML -->
<ThreadGroup>
    <stringProp name="ThreadGroup.num_threads">30</stringProp>
    
    <!-- PrediÃ§Ã£o ML -->
    <HTTPSamplerProxy>
        <stringProp name="HTTPSampler.path">/api/predict</stringProp>
        <stringProp name="HTTPSampler.method">POST</stringProp>
        <elementProp name="HTTPsampler.Arguments">
            <Arguments>
                <Argument name="baseline_value">140</Argument>
                <Argument name="accelerations">3</Argument>
                <!-- ... outros parÃ¢metros -->
            </Arguments>
        </elementProp>
    </HTTPSamplerProxy>
</ThreadGroup>
```

---

## ğŸ› ï¸ **Scripts Auxiliares**

### ğŸ¯ **Gerador de Dados de Teste**
```python
# generate_test_data.py
import csv
import random
from faker import Faker

def gerar_dados_gestantes(quantidade=1000):
    """Gera dados de teste para gestantes"""
    fake = Faker('pt_BR')
    
    with open('dados/gestantes.csv', 'w', newline='') as file:
        writer = csv.writer(file)
        writer.writerow(['patient_id', 'patient_name', 'patient_cpf', 'gestational_age'])
        
        for i in range(quantidade):
            writer.writerow([
                f'TEST{i:04d}',
                fake.name(),
                fake.cpf(),
                random.randint(20, 40)
            ])

def gerar_parametros_ml(quantidade=5000):
    """Gera parÃ¢metros para testes ML"""
    # Implementar geraÃ§Ã£o de 21 features realistas
    pass
```

### ğŸ“Š **Executor AutomÃ¡tico**
```python
# run_load_tests.py
import subprocess
import argparse
import datetime
import os

def executar_teste_jmeter(cenario, relatorio=True):
    """
    Executa teste JMeter e gera relatÃ³rios
    """
    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
    resultado_file = f'resultados/{cenario}_{timestamp}.jtl'
    relatorio_dir = f'resultados/relatorios_html/{cenario}_{timestamp}'
    
    # Comando JMeter
    cmd = [
        'jmeter',
        '-n',
        '-t', f'cenarios/{cenario}.jmx',
        '-l', resultado_file
    ]
    
    if relatorio:
        cmd.extend(['-e', '-o', relatorio_dir])
    
    # Executar
    print(f"ğŸš€ Executando teste: {cenario}")
    result = subprocess.run(cmd, capture_output=True, text=True)
    
    if result.returncode == 0:
        print(f"âœ… Teste concluÃ­do: {cenario}")
        if relatorio:
            print(f"ğŸ“Š RelatÃ³rio: {relatorio_dir}/index.html")
    else:
        print(f"âŒ Erro no teste: {result.stderr}")
    
    return result.returncode == 0

def main():
    parser = argparse.ArgumentParser(description='Executor de Testes de Carga')
    parser.add_argument('--scenario', choices=['load_test', 'stress_test', 'spike_test', 'endurance_test', 'all'])
    parser.add_argument('--report', action='store_true', help='Gerar relatÃ³rio HTML')
    
    args = parser.parse_args()
    
    if args.scenario == 'all':
        cenarios = ['load_test', 'stress_test', 'spike_test']
    else:
        cenarios = [args.scenario]
    
    for cenario in cenarios:
        executar_teste_jmeter(cenario, args.report)

if __name__ == '__main__':
    main()
```

---

## ğŸ“Š **InterpretaÃ§Ã£o de Resultados**

### ğŸ“ˆ **GrÃ¡ficos Importantes**
1. **Response Time Over Time**: TendÃªncia de tempo de resposta
2. **Throughput vs Users**: RelaÃ§Ã£o carga vs throughput
3. **Error Rate**: Taxa de erro ao longo do tempo
4. **Resource Utilization**: Uso de CPU/MemÃ³ria

### ğŸ¯ **Indicadores de Performance**
```python
def avaliar_performance(resultados):
    """
    Avalia se o sistema passou nos testes
    """
    criterios = {
        'tempo_resposta_ok': resultados['tempo_medio'] < 500,
        'percentil_95_ok': resultados['percentil_95'] < 1000,
        'taxa_erro_ok': resultados['taxa_erro'] < 0.01,
        'throughput_ok': resultados['throughput'] > 100,
        'disponibilidade_ok': resultados['disponibilidade'] > 0.995
    }
    
    aprovado = all(criterios.values())
    return aprovado, criterios
```

---

## ğŸ”„ **IntegraÃ§Ã£o com CI/CD**

### ğŸš€ **GitHub Actions**
```yaml
name: Load Tests
on:
  schedule:
    - cron: '0 2 * * 1'  # Segunda-feira Ã s 2h

jobs:
  load-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup JMeter
        run: |
          wget https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.6.3.zip
          unzip apache-jmeter-5.6.3.zip
          export PATH=$PATH:$PWD/apache-jmeter-5.6.3/bin
      
      - name: Start FetalCare System
        run: |
          cd back-end
          python app_with_database.py &
          sleep 30
      
      - name: Run Load Tests
        run: |
          cd back-end/Testes/Carga
          python scripts/run_load_tests.py --scenario load_test --report
      
      - name: Upload Results
        uses: actions/upload-artifact@v3
        with:
          name: load-test-results
          path: back-end/Testes/Carga/resultados/
```

---

## ğŸ¯ **Melhores PrÃ¡ticas**

### âœ… **PreparaÃ§Ã£o dos Testes**
1. **Ambiente Isolado**: Usar ambiente dedicado para testes
2. **Dados Realistas**: Usar dados similares Ã  produÃ§Ã£o
3. **Monitoramento**: Monitorar recursos durante testes
4. **Baseline**: Estabelecer baseline antes de mudanÃ§as

### ğŸ“Š **Durante a ExecuÃ§Ã£o**
1. **Warm-up**: Permitir aquecimento do sistema
2. **Ramp-up Gradual**: Aumentar carga gradualmente
3. **Monitoramento Ativo**: Acompanhar mÃ©tricas em tempo real
4. **Logs Detalhados**: Manter logs para anÃ¡lise posterior

### ğŸ” **AnÃ¡lise de Resultados**
1. **MÃºltiplas ExecuÃ§Ãµes**: Executar testes mÃºltiplas vezes
2. **AnÃ¡lise EstatÃ­stica**: Usar mÃ©dias e percentis
3. **CorrelaÃ§Ã£o**: Correlacionar mÃ©tricas de aplicaÃ§Ã£o e sistema
4. **DocumentaÃ§Ã£o**: Documentar achados e recomendaÃ§Ãµes

---

## ğŸ† **ConclusÃ£o**

Esta estrutura de testes de carga com **Apache JMeter** fornece uma base sÃ³lida para avaliar a performance do Sistema FetalCare. Os testes cobrem cenÃ¡rios realistas e fornecem mÃ©tricas detalhadas para garantir que o sistema possa suportar a carga esperada em produÃ§Ã£o.

### ğŸ¯ **PrÃ³ximos Passos**
1. **Implementar CenÃ¡rios**: Criar arquivos .jmx especÃ­ficos
2. **Configurar Monitoramento**: Setup de mÃ©tricas detalhadas
3. **Automatizar ExecuÃ§Ã£o**: Scripts para execuÃ§Ã£o regular
4. **Integrar CI/CD**: Testes automÃ¡ticos em pipeline

---

**ğŸ“… Ãšltima AtualizaÃ§Ã£o**: 03/07/2025  
**ğŸ”¬ ResponsÃ¡vel**: Sistema de Testes de Performance  
**ğŸ“Š VersÃ£o**: Apache JMeter 5.6.3  
**ğŸ¥ Sistema**: FetalCare - Monitoramento Fetal Inteligente 